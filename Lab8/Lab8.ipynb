{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Machine Learning and Vision Lab</h1>\n",
    "<h4 align=\"center\">Dr. Mohammadzadeh</h4>\n",
    "<h4 align=\"center\">Sharif University of Technology, Fall 2023</h4>\n",
    "<h4 align=\"center\">Amir Hossein Yari - 99102507</h4>\n",
    "<h4 align=\"center\">Lab 8 - Optical Flow</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required package\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a video capture object (camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Hyperparameters\n",
    "maxCorners = 100\n",
    "\n",
    "# Generate random colors for visualizing feature points\n",
    "color = np.random.randint(0, 255, (maxCorners, 3))\n",
    "\n",
    "# Parameters for goodFeaturesToTrack\n",
    "feature_params = dict(maxCorners=maxCorners,\n",
    "                      qualityLevel=0.3,\n",
    "                      minDistance=7,\n",
    "                      blockSize=7)\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Take the first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find good features to track in the first frame\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while True:\n",
    "    # Read the current frame\n",
    "    ret, frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate optical flow using Lucas-Kanade method\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel().astype(int)\n",
    "        c, d = old.ravel().astype(int)\n",
    "\n",
    "        # Draw line and circle for each feature point\n",
    "        mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "\n",
    "    # Combine the frame with the mask to visualize the tracks\n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Optical Flow', img)\n",
    "\n",
    "    # Press 'Esc' to exit the loop\n",
    "    k = cv2.waitKey(25)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Update the previous frame and feature points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a video capture object (camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Read the first frame\n",
    "ret, first_frame = cap.read()\n",
    "\n",
    "# Convert the first frame to grayscale\n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create a mask with maximum saturation\n",
    "mask = np.zeros_like(first_frame)\n",
    "mask[..., 1] = 255  # Saturation to maximum\n",
    "\n",
    "while True:\n",
    "    # Read the current frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display the input frame\n",
    "    cv2.imshow(\"Input\", frame)\n",
    "\n",
    "    # Convert the current frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate dense optical flow using the Farneback method\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # Calculate magnitude and angle of the 2D vectors\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "\n",
    "    # Set image hue according to the optical flow direction\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "\n",
    "    # Set image value according to the optical flow magnitude (normalized)\n",
    "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Convert HSV to RGB (BGR) color representation\n",
    "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Display the dense optical flow\n",
    "    cv2.imshow(\"Dense Optical Flow\", rgb)\n",
    "\n",
    "    # Update the previous frame\n",
    "    prev_gray = gray\n",
    "\n",
    "    # Press 'Esc' to exit the loop\n",
    "    k = cv2.waitKey(25)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Happy Video Dense Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the main folder\n",
    "main_folder = \"happy videos\"\n",
    "\n",
    "# Create a dictionary to store optical flow results for each subfolder\n",
    "optical_flow_dict_happy = []\n",
    "\n",
    "# Iterate through each subfolder\n",
    "for subfolder in os.listdir(main_folder):\n",
    "    subfolder_path = os.path.join(main_folder, subfolder)\n",
    "    hist_list = []\n",
    "\n",
    "    first_time = True\n",
    "    for image_file in os.listdir(subfolder_path):\n",
    "        image_path = os.path.join(subfolder_path, image_file)\n",
    "\n",
    "        if first_time:\n",
    "            # Read the first frame\n",
    "            prev_frame = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            prev_frame = prev_frame[100:750, 350:800]\n",
    "            first_time = False\n",
    "            continue\n",
    "\n",
    "        current_frame = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        current_frame = current_frame[100:750, 350:800]\n",
    "\n",
    "        # Calculate dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_frame, current_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        # Calculate histograms of flow magnitudes in both x and y directions\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        hist= np.histogram(ang.ravel(), bins=np.linspace(0,2*np.pi,9))[0]\n",
    "\n",
    "        # Store the optical flow results for the current frame\n",
    "        hist_list.append(hist)\n",
    "\n",
    "        # Update the previous frame for the next iteration\n",
    "        prev_frame = current_frame\n",
    "\n",
    "    hists_array = np.array(hist_list)\n",
    "    combine_results = np.concatenate((np.mean(hists_array, axis=0), np.max(hists_array, axis=0)))\n",
    "    # Add the list of optical flow results to the dictionary with the subfolder name as the key\n",
    "    optical_flow_dict_happy.append(combine_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Surprise Video Dense Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the main folder\n",
    "main_folder = \"surprise videos\"\n",
    "\n",
    "# Create a dictionary to store optical flow results for each subfolder\n",
    "optical_flow_dict_surprise = []\n",
    "\n",
    "# Iterate through each subfolder\n",
    "for subfolder in os.listdir(main_folder):\n",
    "    subfolder_path = os.path.join(main_folder, subfolder)\n",
    "    hist_list = []\n",
    "\n",
    "    first_time = True\n",
    "    for image_file in os.listdir(subfolder_path):\n",
    "        image_path = os.path.join(subfolder_path, image_file)\n",
    "\n",
    "        if first_time:\n",
    "            # Read the first frame\n",
    "            prev_frame = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            prev_frame = prev_frame[100:750, 350:800]\n",
    "            first_time = False\n",
    "            continue\n",
    "\n",
    "        current_frame = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        current_frame = current_frame[100:750, 350:800]\n",
    "\n",
    "        # Calculate dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_frame, current_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        # Calculate histograms of flow magnitudes in both x and y directions\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        hist= np.histogram(ang.ravel(), bins=np.linspace(0,2*np.pi,9))[0]\n",
    "\n",
    "        # Store the optical flow results for the current frame\n",
    "        hist_list.append(hist)\n",
    "\n",
    "        # Update the previous frame for the next iteration\n",
    "        prev_frame = current_frame\n",
    "\n",
    "    hists_array = np.array(hist_list)\n",
    "    combine_results = np.concatenate((np.mean(hists_array, axis=0), np.max(hists_array, axis=0)))\n",
    "    # Add the list of optical flow results to the dictionary with the subfolder name as the key\n",
    "    optical_flow_dict_surprise.append(combine_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_flow_dict_surprise = np.array(optical_flow_dict_surprise)\n",
    "optical_flow_dict_happy = np.array(optical_flow_dict_happy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00\n",
      "SVM Classifier Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "surprise_labels = np.zeros(len(optical_flow_dict_surprise))\n",
    "happy_labels = np.ones(len(optical_flow_dict_happy))\n",
    "\n",
    "# Concatenate all data and labels\n",
    "all_data = np.concatenate((optical_flow_dict_surprise, optical_flow_dict_happy))\n",
    "all_labels = np.concatenate((surprise_labels, happy_labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    all_data, all_labels, test_size=0.5, random_state=0\n",
    ")\n",
    "\n",
    "# Reshape data for SVM\n",
    "train_data_reshaped = train_data.reshape(len(train_data), -1)\n",
    "test_data_reshaped = test_data.reshape(len(test_data), -1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data_reshaped)\n",
    "train_data_reshaped = scaler.transform(train_data_reshaped)\n",
    "\n",
    "scaler.fit(test_data_reshaped)\n",
    "test_data_reshaped = scaler.transform(test_data_reshaped)\n",
    "\n",
    "# Create and train the SVM classifier\n",
    "classifier = SVC(C=100)\n",
    "classifier.fit(train_data_reshaped, train_labels)\n",
    "# Make predictions on the training set\n",
    "train_predictions = classifier.predict(train_data_reshaped)\n",
    "# Evaluate the performance on the training set\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "# Make predictions on the test set\n",
    "predictions = classifier.predict(test_data_reshaped)\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"SVM Classifier Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00\n",
      "Random Forest Classifier Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    all_data, all_labels, test_size=0.1, random_state=0\n",
    ")\n",
    "\n",
    "# Reshape data for SVM\n",
    "train_data_reshaped = train_data.reshape(len(train_data), -1)\n",
    "test_data_reshaped = test_data.reshape(len(test_data), -1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data_reshaped)\n",
    "train_data_reshaped = scaler.transform(train_data_reshaped)\n",
    "\n",
    "scaler.fit(test_data_reshaped)\n",
    "test_data_reshaped = scaler.transform(test_data_reshaped)\n",
    "\n",
    "# Create and train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=0)\n",
    "rf_classifier.fit(train_data_reshaped, train_labels)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_predictions = rf_classifier.predict(train_data_reshaped)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = rf_classifier.predict(test_data_reshaped)\n",
    "\n",
    "# Evaluate the performance of Random Forest Classifier\n",
    "rf_accuracy = accuracy_score(test_labels, rf_predictions)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Random Forest Classifier Accuracy: {rf_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00\n",
      "AdaBoost Classifier Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    all_data, all_labels, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "# Reshape data for SVM\n",
    "train_data_reshaped = train_data.reshape(len(train_data), -1)\n",
    "test_data_reshaped = test_data.reshape(len(test_data), -1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data_reshaped)\n",
    "train_data_reshaped = scaler.transform(train_data_reshaped)\n",
    "\n",
    "scaler.fit(test_data_reshaped)\n",
    "test_data_reshaped = scaler.transform(test_data_reshaped)\n",
    "\n",
    "# Create a base Decision Tree classifier\n",
    "base_classifier = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Create and train the AdaBoost classifier with the base classifier\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=15, random_state=0)\n",
    "adaboost_classifier.fit(train_data_reshaped, train_labels)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_predictions = adaboost_classifier.predict(train_data_reshaped)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "adaboost_predictions = adaboost_classifier.predict(test_data_reshaped)\n",
    "\n",
    "# Evaluate the performance of AdaBoost Classifier\n",
    "adaboost_accuracy = accuracy_score(test_labels, adaboost_predictions)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"AdaBoost Classifier Accuracy: {adaboost_accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
